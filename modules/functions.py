from modules.gemini import llm
from langchain_core.messages import HumanMessage, SystemMessage
import logging
import time

# Prompt do sistema
prompt_sistema = """
Voc√™ √© o HeyDev, assistente virtual oficial do Programa Jovem Programador de Santa Catarina,
criado pelo SENAC e SEPROSC.

Use o conte√∫do fornecido abaixo como base principal para suas respostas. 
Caso o contexto n√£o contenha a informa√ß√£o solicitada, utilize seu conhecimento pr√©vio 
para responder de forma correta sobre o Programa Jovem Programador.

Responda sobre: o programa, suas inscri√ß√µes, requisitos, cidades participantes, cronograma, 
hackathon, curso oferecido e benef√≠cios.

Explique o que for necess√°rio para ajudar o usu√°rio a entender o funcionamento do Programa.
Mantenha sempre o foco no Jovem Programador. Se a pergunta for sobre outro tema, 
explique gentilmente que foge do assunto.

Responda sempre em portugu√™s do Brasil, com tom simp√°tico, claro e natural.
Evite respostas muito longas (m√°ximo 4 linhas).

"""

# Detecta respostas gen√©ricas
def resposta_invalida(resposta: str) -> bool:
    sinais = [
        "n√£o sei", "n√£o tenho certeza", "n√£o encontrei", "n√£o posso responder",
        "desculpe", "n√£o est√° claro", "n√£o identifiquei", "n√£o tenho dados"
    ]
    return any(sinal in resposta.lower() for sinal in sinais)

# Resume respostas longas
def resumir_resposta(texto: str) -> str:
    if len(texto) <= 500:
        return texto
    logging.info("‚úÇÔ∏è Resposta longa ‚Äî resumindo...")
    try:
        mensagens = [
            SystemMessage(content="Resuma o texto abaixo em at√© 4 linhas, mantendo o sentido e o tom."),
            HumanMessage(content=texto)
        ]
        resumo = llm.invoke(mensagens)
        return getattr(resumo, "content", str(resumo)).strip()
    except Exception as e:
        logging.error(f"Erro ao resumir: {e}")
        return texto[:500] + "..."

# Gera resposta com base no contexto
def responder_com_contexto(msg: str, contexto: str) -> str:
    inicio = time.time()
    try:
        mensagens = [
            SystemMessage(content=prompt_sistema),
            HumanMessage(
                content=(
                    f"Com base no contexto abaixo, responda de forma breve e direta.\n\n"
                    f"--- CONTEXTO ---\n{contexto.strip()}\n\n"
                    f"--- PERGUNTA ---\n{msg.strip()}"
                )
            )
        ]
        resposta = llm.invoke(mensagens)
        resposta_texto = getattr(resposta, "content", str(resposta)).strip()

        if resposta_invalida(resposta_texto):
            return (
                "üîç N√£o encontrei essa informa√ß√£o com clareza no site oficial.<br>"
                "üìû Para mais detalhes, entre em contato com o SENAC: (48) 3341-9120."
            )

        resposta_final = resumir_resposta(resposta_texto)
        logging.info(f"‚úÖ Resposta gerada em {time.time() - inicio:.2f}s")
        return resposta_final

    except Exception as e:
        logging.error(f"Erro no chatbot: {e}")
        return (
            "‚ö†Ô∏è Ops! Houve um problema tempor√°rio com o assistente.<br>"
            "Por favor, tente novamente em alguns segundos."
        )

# L√™ o conte√∫do de um arquivo
def ler_conteudo_arquivo(nome_arquivo: str) -> str:
    try:
        with open(nome_arquivo, "r", encoding="utf-8") as arquivo:
            return arquivo.read()
    except Exception as e:
        logging.error(f"Erro ao ler arquivo: {e}")
        return ""
